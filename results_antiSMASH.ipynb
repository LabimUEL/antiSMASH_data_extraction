{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f446e-0f85-48c2-a79b-ba03edf6acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2560a9-988f-4d8f-a25d-ca11f14c63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cria um arquivo para adicionar os nomes e numeros dos clusters\n",
    "\n",
    "clusters_names_csv = open('clustersname.csv','w')\n",
    "\n",
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(dirpath, file_name)\n",
    "        \n",
    "        ### busca arquivos dentro da pasta /knownclusterblast, output do antiSMASH\n",
    "        if dirpath == './knownclusterblast':\n",
    "            \n",
    "            ### extrai o numero do cluster\n",
    "            \n",
    "            str_fn = str(file_name).replace('.txt','').replace('c','').split('_')[-1]\n",
    "            \n",
    "            ### abre o arquivo de texto e le as linhas\n",
    "            \n",
    "            file = open(file_path,'r')            \n",
    "            lines = file.readlines()\n",
    "            cluster_name = ''\n",
    "            \n",
    "            ### Corre pelas linhas do arquivo com enumerate para conseguir manipular indexes das linhas\n",
    "            \n",
    "            for index, lin in enumerate(lines):\n",
    "                if lin.startswith('Significant hits'):\n",
    "                    if index > 0:\n",
    "                        previous = lines[index - 1]\n",
    "                    if index < (len(lines) - 1):\n",
    "                        next_ = lines[index + 1]\n",
    "                        \n",
    "                        ### obtem o nome (caso tenha) do cluster, na linha seguinte a Sginificant Hits\n",
    "                        \n",
    "                        if next_.startswith('1.'):\n",
    "                            cluster_name = next_.replace('\\t','_').split('_')[-1]\n",
    "                        else:\n",
    "                            cluster_name = 'region'\n",
    "            clusters_names_csv.write(str_fn+',')\n",
    "            if cluster_name != None:\n",
    "                clusters_names_csv.write(str(cluster_name)+'\\n')\n",
    "        else:\n",
    "            pass\n",
    "clusters_names_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e8fef-9524-4bf7-bc6e-b0b0f8461be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tratamento do CSV criado anteriormente\n",
    "### pulando linhas e espaços em branco\n",
    "\n",
    "clust_name = pd.read_csv('clustersname.csv', \n",
    "                         skip_blank_lines=True, \n",
    "                         header=None)\n",
    "\n",
    "### Renomeia as colunas\n",
    "\n",
    "clust_name.rename(columns={0:'clust_num',1:'nome'}, inplace = True)\n",
    "\n",
    "\n",
    "### Coloca em ordem com base no numero do cluster\n",
    "df2 = clust_name.sort_values(by='clust_num')\n",
    "\n",
    "### adiciona a string \"region\" nos clusters onde nao foi possivel obter o nome\n",
    "df2.fillna('region', inplace = True)\n",
    "\n",
    "### Trata os indexes\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.index = df2.index + 1\n",
    "print(df2)\n",
    "        \n",
    "clusters_names_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e92091-d05d-47e5-ba4e-62f046f28921",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for dirname in dirnames:\n",
    "        pastas = dirname\n",
    "    for file_name in files:\n",
    "        \n",
    "        ### Seleciona os arquivos dos clusters output do antiSMASH\n",
    "        \n",
    "        if file_name.startswith('NZ_CP059318.1.region0') and file_name.endswith('.gbk'):\n",
    "            \n",
    "            cds_motifs_list = []\n",
    "            cds_motifs_counts = {}\n",
    "            \n",
    "            CDS_smCOG_list = []\n",
    "            CDS_smCOG_count = {}\n",
    "\n",
    "            \n",
    "            \n",
    "            ### Obtem o numero do clusters dentro do resultado do antiSMASH\n",
    "            \n",
    "            reg_num0 = file_name.split('.')[-2][-2:]\n",
    "            \n",
    "            ### Obtem o numero de acesso da cepa que foi analisada pelo antiSMASH\n",
    "            \n",
    "            acc_clust = file_name.split('.')[0]\n",
    "                        \n",
    "            ### Abre o arquivo\n",
    "            \n",
    "            record = SeqIO.read(file_name, \"genbank\")\n",
    "            #print('\\n'+file_name)\n",
    "            \n",
    "            \n",
    "            ### Corre sobre as features do arquivo gbk\n",
    "            for features in record.features:\n",
    "                \n",
    "                ### Trata e extrai as informações de features do tipo CDS_motifs\n",
    "                ### Usa os qualifiers 'note' e 'aSTool'\n",
    "                if features.type == 'CDS_motif':\n",
    "                    if features.qualifiers.get('note') != None:\n",
    "                        cdsmotif_note = features.qualifiers.get('note')[0]\n",
    "                        cdsmotif_note_f = cdsmotif_note.split(':')[1].strip()\n",
    "                        if cdsmotif_note_f not in cds_motifs_list:\n",
    "                            cds_motifs_list.append(cdsmotif_note_f)\n",
    "                            cds_motifs_counts[cdsmotif_note_f] = 0\n",
    "                        cds_motifs_counts[cdsmotif_note_f] += 1\n",
    "                        \n",
    "                    elif features.qualifiers.get('aSTool') != None:\n",
    "                        #print(features.qualifiers.get('aSTool'))\n",
    "                        labels_motifs = str(features.qualifiers.get('label')).strip('[]\"\\'\"')\n",
    "                        if labels_motifs not in cds_motifs_list:\n",
    "                            cds_motifs_list.append(labels_motifs)\n",
    "                            #print(labels_motifs)\n",
    "                            cds_motifs_counts[labels_motifs] = 0\n",
    "                        cds_motifs_counts[labels_motifs] += 1                        \n",
    "                        \n",
    "                    else:\n",
    "                        cdsmotif_note = None \n",
    "                        cdsmotif_note_f = None\n",
    "                \n",
    "                if features.type == 'CDS':\n",
    "                    gen_func = features.qualifiers.get('gene_functions')\n",
    "                    if gen_func != None:\n",
    "                        for items in gen_func:                        \n",
    "                            if 'smcogs' in items:\n",
    "                                SMCOG_type0 = re.search(\"SMCOG[0-9]*:.*[(]\", str(items))\n",
    "                                SMCOG_type1 = SMCOG_type0.group().replace(\"(\",\"\").strip()\n",
    "                                if SMCOG_type1 not in CDS_smCOG_list:\n",
    "                                    CDS_smCOG_list.append(SMCOG_type1)\n",
    "                                    CDS_smCOG_count[SMCOG_type1] = 0\n",
    "                                CDS_smCOG_count[SMCOG_type1] += 1\n",
    "                                \n",
    "                            else:\n",
    "                                pass\n",
    "                    else:\n",
    "                        pass\n",
    "            \n",
    "            ### Cria 1 DataFrame pra cada cluster contendo a contagem de cada feature extraído\n",
    "            \n",
    "            df1 = pd.DataFrame([cds_motifs_counts], index=[1])\n",
    "            \n",
    "            ### Extrai nome do cluster baseado no seu numero de acordo com a DataFrame dos clusters_names\n",
    "            \n",
    "            cluster_name_ = df2.loc[df2[\"clust_num\"] == int(reg_num0), \"nome\"]\n",
    "            \n",
    "            ### transforma a Series obtida em DataFrame\n",
    "            \n",
    "            cf = cluster_name_.to_frame()\n",
    "            \n",
    "            ### Adiciona a coluna 'nome' com o nome do cluster obtido anteriormente e a coluna 'acc' com numero de acesso da cepa\n",
    "            \n",
    "            df1['nome'] = cf.iloc[0,0]\n",
    "            df1['acc'] = acc_clust\n",
    "            \n",
    "            ### Salva o arquivo numa pasta de CSV de cada cluster\n",
    "            df1.to_csv('data_frame/tempfile_motifs_cluster'+reg_num0+'.csv')\n",
    "            \n",
    "            \n",
    "            cds_df = pd.DataFrame([CDS_smCOG_count], index=[1])\n",
    "            cluster_name_1 = df2.loc[df2[\"clust_num\"] == int(reg_num0), \"nome\"]\n",
    "            cf1 = cluster_name_1.to_frame()\n",
    "            cds_df['nome'] = cf1.iloc[0,0] \n",
    "            cds_df['acc'] = acc_clust\n",
    "            cds_df.to_csv('data_frame/tempfile_smCOG'+reg_num0+'.csv')\n",
    "\n",
    "#print(CDS_smCOG_count)\n",
    "#print(CDS_smCOG_list)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd50a50-a5ca-4b17-b481-9cb9d23a7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### concatena todos os CSV criados eu um arquivo\n",
    "\n",
    "files_paths0 = []\n",
    "\n",
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for file_name in files:\n",
    "        file_path0 = os.path.join(dirpath, file_name)\n",
    "        if dirpath == './data_frame' and file_name.startswith('tempfile_motifs'):\n",
    "            \n",
    "            files_paths0.append(file_path0)\n",
    "            \n",
    "df5 = pd.concat(map(pd.read_csv, files_paths0), ignore_index=True)\n",
    "df5 = df5.fillna(0)\n",
    "df5.to_csv('data_frame/all_features_CDS_motifs.csv', header=True)\n",
    "\n",
    "#print(files_paths0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5eee4b-7e7a-4ff6-b84e-80dd0a9a317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_paths1 = []\n",
    "\n",
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for file_name in files:\n",
    "        file_path1 = os.path.join(dirpath, file_name)\n",
    "        if dirpath == './data_frame' and file_name.startswith('tempfile_smCOG'):\n",
    "            \n",
    "            files_paths1.append(file_path1)\n",
    "            \n",
    "df6 = pd.concat(map(pd.read_csv, files_paths1), ignore_index=True)\n",
    "df6 = df6.fillna(0)\n",
    "df6.to_csv('data_frame/all_features_CDS_smCOG.csv', header=True)\n",
    "\n",
    "#print(files_paths1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfa271-7fbb-4169-84f1-62872135a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for file_name in files:\n",
    "        file_path1 = os.path.join(dirpath, file_name)\n",
    "        if file_name.startswith('tempfile_'):\n",
    "            os.remove(file_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a98c7-e916-4ce6-9df2-d04161d708fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCDSMotif(feature):\n",
    "    note_text = feature.qualifiers['note'][0]\n",
    "    if \"(\" not in note_text: #CDS name not formatted properly\n",
    "        return None\n",
    "    motif_name = note_text[0:note_text.index(\"(\")-1]\n",
    "    return motif_name\n",
    "\n",
    "def processCDS(feature):\n",
    "    smCOG_type = None\n",
    "    for note in feature.qualifiers[\"note\"]:\n",
    "        if \"smCOG\" in note:\n",
    "            if \":\" not in note or \"(\" not in note:\n",
    "                continue\n",
    "            smCOG_type = note[note.index(\":\")+2:note.index(\"(\")-1]\n",
    "    return smCOG_type\n",
    "\n",
    "def processPFAM(feature, score_cutoff=20):\n",
    "    score = float(feature.qualifiers[\"score\"][0])\n",
    "    if score <score_cutoff:\n",
    "        return None, None\n",
    "    domain_description = feature.qualifiers[\"description\"][0]\n",
    "    pfam_id = feature.qualifiers[\"db_xref\"][0]\n",
    "    pfam_id = pfam_id[pfam_id.find(\" \")+1:len(pfam_id)]\n",
    "    return domain_description, pfam_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775d0dc-e127-46b5-84c2-e0189301a307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
