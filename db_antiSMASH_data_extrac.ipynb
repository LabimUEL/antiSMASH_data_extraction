{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbf62d8-14ee-47d1-97ac-763ba00aa528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9f61b-8e38-46e1-9b23-acc5ff19b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_activ = pd.read_csv('products_activity.csv', on_bad_lines='skip')\n",
    "prod_activ['BGC_id'] = ''\n",
    "print(prod_activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7cc8f-3f5f-4ced-9a1d-1b8b8f3547ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BGCs_with_activity_list = []\n",
    "\n",
    "for dirpath, dirnames, files in os.walk('../'):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('json'):\n",
    "            with open(file_name,'r') as json_read:\n",
    "                print(file_name)\n",
    "                BGC_id = file_name.replace('.json','')\n",
    "                bgc_json = json.load(json_read)\n",
    "                comp = bgc_json['cluster']['compounds']\n",
    "                for i in comp:\n",
    "                    product = i['compound']\n",
    "                    print(product)\n",
    "                    product_ = product.replace('\\'', '').replace('β', '_beta').split(' ')[0]                 \n",
    "                    print(product_)\n",
    "                    try:\n",
    "                        const = prod_activ.loc[(prod_activ['cluster_name']).str.contains(str(product_))]\n",
    "                        if const.empty == False:\n",
    "                            gbk_file_name = file_name.replace('.json','.gbk')\n",
    "                            BGCs_with_activity_list.append(gbk_file_name)\n",
    "                        else:\n",
    "                            pass                   \n",
    "                    except:\n",
    "                        print(\"Error\")\n",
    "\n",
    "                    try:\n",
    "                        prod_activ.loc[(prod_activ['cluster_name']).str.contains(str(product_)), ['BGC_id']] = BGC_id\n",
    "                    except:\n",
    "                        print('Error2')\n",
    "                        \n",
    "print(prod_activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06e42ed-fac3-48b6-a1d8-cc2d6c476717",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_out = pd.read_csv('../pfam.tsv', on_bad_lines='skip', delimiter='\\t')\n",
    "\n",
    "pfam_out['BGC_id'] = pfam_out['query name'].str.split('|').str[0]\n",
    "\n",
    "queries = pfam_out['query name'].str.split('|').str[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f7239-1e7c-45ae-9754-4d5eaa88ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 150)\n",
    "\n",
    "pfam_acc = pfam_out[['query name', 'accession','BGC_id']]\n",
    "\n",
    "pf2 = pfam_acc.groupby('query name').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b910f-47e0-4689-9d49-326f6a70592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descomentar a linha a seguir caso ainda não exista a pasta 'data_frame_00'\n",
    "\n",
    "#os.mkdir('data_frame_00')\n",
    "\n",
    "for i in pf2['BGC_id'].unique():\n",
    "    a1 = pf2.loc[pf2['BGC_id'] == i]\n",
    "    \n",
    "    print(len(pf2['BGC_id'].unique()))\n",
    "    \n",
    "    values = a1['accession'].value_counts().keys().tolist()\n",
    "    counts = a1['accession'].value_counts().tolist()\n",
    "    \n",
    "    PFAM_ID = {}\n",
    "    for keys in values:\n",
    "        for count in counts:\n",
    "            PFAM_ID[keys] = count\n",
    "            counts.remove(count)\n",
    "            break\n",
    "    \n",
    "    PFAM_ID_df = pd.DataFrame([PFAM_ID])\n",
    "    PFAM_ID_df['BGC_id'] = i\n",
    "    PFAM_ID_df.to_csv('data_frame_00/'+i+'tempfile_PFAM_ID.csv')\n",
    "\n",
    "files_paths = []\n",
    "check = 'checkpoint'\n",
    "\n",
    "for dirpath, dirnames, files in os.walk('./'):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(dirpath, file_name)\n",
    "        if file_name.startswith('BGC') and file_name.endswith('.csv') and check not in file_name:\n",
    "            files_paths.append(file_path)\n",
    "\n",
    "df1 = pd.concat(map(pd.read_csv, files_paths), ignore_index=False)\n",
    "df1 = df1.fillna(0)\n",
    "df1.to_csv('data_frame_00/all_features_PFAM_ID.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
